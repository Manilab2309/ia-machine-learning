{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manilab2309/ia-machine-learning/blob/main/lab/NB_analyst_broker_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3TkIlVS6yok",
        "outputId": "7709fa93-3d45-49a8-eb3e-13a51eaacd88"
      },
      "outputs": [],
      "source": [
        "print(\"Welcome aboard! Ramon!, now you're working on Jupyter & Visual Studio Code\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK9gwzlvNnIU"
      },
      "source": [
        "# ***Inicialization***\n",
        "Global configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHphg4TBNlRK"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import calendar\n",
        "import math\n",
        "\n",
        "# Colab limits by default table size to 25 columns\n",
        "# from google.colab.data_table import DataTable\n",
        "# DataTable.max_columns = 100\n",
        "# pd.set_option('display.max_rows', None) Uncomment if you wish to see entire data table (not recommended)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqVIPzmo18PJ"
      },
      "source": [
        "# Data Loader\n",
        "Read sources:\n",
        "\n",
        "\n",
        "*   Ibex35\n",
        "*   IPC\n",
        "*   Euribor\n",
        "*   Gold\n",
        "*   Brent\n",
        "*   Dolar/Euro\n",
        "*   Mortality EU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjwDX4Uly7tc"
      },
      "source": [
        "## Read Ibex35 2023\n",
        "Read from Github.com Ibex35 2023\n",
        "\n",
        "Source: https://es.finance.yahoo.com/quote/%5EIBEX/history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqJaIfiozJHn"
      },
      "outputs": [],
      "source": [
        "df_ibex_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/ibex35_2023.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GReiHJ7IzRJ6"
      },
      "source": [
        "## Read IPC 2023\n",
        "Read from Github.com IPC 2023 in this example we added two interesting clauses\n",
        " - on_bad_lines='skip' --> Very useful to force read csv files\n",
        " - sep = ';'           --> To customize char delimiter, by default is , When you get csv from excel, its set ; as delimiter then conflicts with panda parser.\n",
        "\n",
        "Source: https://www.ine.es/prensa/ipc_tabla.htm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTvoPOPOzRAd"
      },
      "outputs": [],
      "source": [
        "df_ipc_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/IPC-2023.csv', on_bad_lines='skip', sep = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHwgqv0YzQ41"
      },
      "source": [
        "## Read Euribor 2023\n",
        "Read from Github.com Euribor 2023\n",
        "\n",
        "Source: https://datosmacro.expansion.com/hipotecas/euribor?dr=2024-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpaBL5OwzQuj"
      },
      "outputs": [],
      "source": [
        "df_euribor_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/Euribor-2023.csv', on_bad_lines='skip', sep = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99SWOGIczQkT"
      },
      "source": [
        "## Read Gold 2023\n",
        "Read from Github.com Oro 2023\n",
        "\n",
        "Source: https://es.finance.yahoo.com/quote/GC%3DF/history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaaHxCuSzQaC"
      },
      "outputs": [],
      "source": [
        "df_gold_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/Oro-2023.csv', on_bad_lines='skip', sep = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRdHaafdzQPz"
      },
      "source": [
        "## Read Brent 2023\n",
        "Read from Github.com Petroleo 2023\n",
        "Source: https://es.finance.yahoo.com/quote/BZ%3DF/history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMGGtDSjzQGF"
      },
      "outputs": [],
      "source": [
        "df_brent_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/Brent-2023.csv', on_bad_lines='skip', sep = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi_42P4hzP5V"
      },
      "source": [
        "## Read Dolar/Euro 2023\n",
        "Read from Github.com $/Euro 2023\n",
        "\n",
        "Source: https://es.finance.yahoo.com/quote/EURUSD%3DX/history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4_qXw35zPq4"
      },
      "outputs": [],
      "source": [
        "df_dolar_euro_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/Dolar-Euro-2023.csv', on_bad_lines='skip', sep = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1zLk4sHzPQQ"
      },
      "source": [
        "## Excess mortality by month Euro 2023\n",
        "Read from Github.com Mortality European\n",
        "\n",
        "Source: https://ec.europa.eu/eurostat/databrowser/view/demo_mexrt/default/table?lang=en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLyUKLUL06HT"
      },
      "outputs": [],
      "source": [
        "df_excess_mortality_2023 = pd.read_csv('https://raw.githubusercontent.com/Manilab2309/ia-machine-learning/main/samples/Excess_mortality_by_month_2023.csv', on_bad_lines='skip', sep = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Formatter\n",
        "\n",
        " Global considerations:\n",
        " - Rename columns to be more specific\n",
        " - Floats will have . as separator decimal position\n",
        " - Floats will have only 2 decimal positions\n",
        " - Dates will have this format: 2023-01-02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Ibex35 2023\n",
        "\n",
        "Ibex35 csv source needs these format actions:\n",
        "\n",
        "- Rename columns\n",
        "- Set . as decimal separator token\n",
        "- set 2 float positions\n",
        "- Convert object to float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_ibex_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual datatypes\n",
        "df_ibex_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns for later merge with other tables with similar named columns\n",
        "df_ibex_2023 = df_ibex_2023.rename(columns={'Fecha': 'Date', 'Open': 'Ibex Open','High': 'Ibex High','Low': 'Ibex Low','Close': 'Ibex Close','Adj Close': 'Ibex Adj Close','Volume': 'Ibex Volume'})\n",
        "df_ibex_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8297.900391 (float64) --> 8297.90 (float64) We only need 2 decimal positions and . with decimal separator token char\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "df_ibex_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter IPC 2023\n",
        "\n",
        "IPC csv needs these format corrections:\n",
        "- Rename columns\n",
        "- Delete % char\n",
        "- set . as decimal token delimiter\n",
        "- set 2 float positions\n",
        "- Dates: dec-23 --> 2023-12-01 (for getting this, we will need an expansion table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_ipc_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual datatypes\n",
        "df_ipc_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename column if you need\n",
        "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
        "\n",
        "#In this example, lets translate headers to english and add % simbol, remember cells must be desired numbers or float format\n",
        "df_ipc_2023 = df_ipc_2023.rename(columns={'Mes IPC': 'Date'})\n",
        "df_ipc_2023 = df_ipc_2023.rename(columns={'IPC Interanual': 'IPC Interanual %'})\n",
        "df_ipc_2023 = df_ipc_2023.rename(columns={'IPC Acum Enero': 'IPC Acum Jan %'})\n",
        "df_ipc_2023 = df_ipc_2023.rename(columns={'IPC Variacion Mensual': 'IPC Month Variation %'})\n",
        "\n",
        "# We can define variables to use in another cells\n",
        "column_A_Renamed = 'Date'\n",
        "column_B_Renamed = 'IPC Interanual %'\n",
        "column_C_Renamed = 'IPC Acum Jan %'\n",
        "column_D_Renamed = 'IPC Month Variation %'\n",
        "\n",
        "df_ipc_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove % char from cells\n",
        "df_ipc_2023[column_B_Renamed] = df_ipc_2023[column_B_Renamed].str.replace(\"%\", \"\")\n",
        "df_ipc_2023[column_C_Renamed] = df_ipc_2023[column_C_Renamed].str.replace(\"%\", \"\")\n",
        "df_ipc_2023[column_D_Renamed] = df_ipc_2023[column_D_Renamed].str.replace(\"%\", \"\")\n",
        "\n",
        "df_ipc_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_ipc_2023[column_B_Renamed] = df_ipc_2023[column_B_Renamed].str.replace(\",\", \".\")\n",
        "df_ipc_2023[column_C_Renamed] = df_ipc_2023[column_C_Renamed].str.replace(\",\", \".\")\n",
        "df_ipc_2023[column_D_Renamed] = df_ipc_2023[column_D_Renamed].str.replace(\",\", \".\")\n",
        "df_ipc_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert object to float\n",
        "df_ipc_2023[column_B_Renamed] = df_ipc_2023[column_B_Renamed].astype('float64')\n",
        "df_ipc_2023[column_C_Renamed] = df_ipc_2023[column_C_Renamed].astype('float64')\n",
        "df_ipc_2023[column_D_Renamed] = df_ipc_2023[column_D_Renamed].astype('float64')\n",
        "df_ipc_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need to transform the dates from: dic-23 to 2023-12-01, then we will have an aproximation to standard date time zones\n",
        "# Documentation: https://strftime.org/\n",
        "# Utils: https://strftime.net/\n",
        "\n",
        "df_ipc_2023['Date'] = pd.to_datetime(df_ipc_2023['Date'],format='%b-%y').dt.strftime('%Y-%m-%d')\n",
        "df_ipc_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we need expand the table\n",
        "\n",
        "# Declare new Dataframe\n",
        "df_ipc_2023_expanded = pd.DataFrame()\n",
        "df_ipc_2023_expanded = pd.DataFrame(columns=[column_A_Renamed, column_B_Renamed, column_C_Renamed, column_D_Renamed])\n",
        "# Variables column_x_Renamed are initialized in previos cell execution\n",
        "\n",
        "for i in df_ipc_2023.index:\n",
        "\n",
        "    instantDate = datetime.datetime.strptime(df_ipc_2023[column_A_Renamed][i], '%Y-%m-%d')\n",
        "    year = instantDate.year\n",
        "    month = instantDate.month\n",
        "    num_days = calendar.monthrange(year, month)[1]\n",
        "    days = [datetime.date(year, month, day).strftime('%Y-%m-%d') for day in range(1, num_days+1)]\n",
        "\n",
        "    for d in days:\n",
        "      # Add values to new dataframe\n",
        "      df_ipc_2023_expanded.loc[len(df_ipc_2023_expanded.index)] = [d, df_ipc_2023[column_B_Renamed][i], df_ipc_2023[column_C_Renamed][i],df_ipc_2023[column_D_Renamed][i]]\n",
        "\n",
        "df_ipc_2023_expanded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Euribor 2023\n",
        "\n",
        "Euribor source needs following format actions:\n",
        "- Delete % char\n",
        "- Set . as decimal token separator\n",
        "- Convert object to float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_euribor_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual datatypes\n",
        "df_euribor_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove % char from cells\n",
        "df_euribor_2023['Euribor Type'] = df_euribor_2023['Euribor Type'].str.replace(\"%\", \"\")\n",
        "df_euribor_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_euribor_2023['Euribor Type'] = df_euribor_2023['Euribor Type'].str.replace(\",\", \".\")\n",
        "df_euribor_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert object to float\n",
        "df_euribor_2023['Euribor Type'] = df_euribor_2023['Euribor Type'].astype('float64')\n",
        "df_euribor_2023.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Gold 2023\n",
        "\n",
        "Gold 2023 csv needs these format corrections:\n",
        "- Rename columns\n",
        "- Set . as decimal separator token\n",
        "- set 2 float positions\n",
        "- Convert object to float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_gold_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual data types\n",
        "df_gold_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In this example, lets translate headers to english and add % simbol, remember cells must be desired numbers or float format\n",
        "df_gold_2023 = df_gold_2023.rename(columns={'Fecha': 'Date', 'Abrir': 'Gold Open','Máx.': 'Gold High','Mín.': 'Gold Low','Cierre': 'Gold Close','Cierre ajus': 'Gold Adj Close','Volumen': 'Gold Volume'})\n",
        "df_gold_2023\n",
        "\n",
        "# We can define variables to use in another cells\n",
        "column_A_Renamed = 'Date'\n",
        "column_B_Renamed = 'Gold Open'\n",
        "column_C_Renamed = 'Gold High'\n",
        "column_D_Renamed = 'Gold Low'\n",
        "column_E_Renamed = 'Gold Close'\n",
        "column_F_Renamed = 'Gold Adj Close'\n",
        "column_G_Renamed = 'Gold Volume'\n",
        "\n",
        "df_gold_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_gold_2023[column_B_Renamed] = df_gold_2023[column_B_Renamed].str.replace(\",\", \".\")\n",
        "df_gold_2023[column_C_Renamed] = df_gold_2023[column_C_Renamed].str.replace(\",\", \".\")\n",
        "df_gold_2023[column_D_Renamed] = df_gold_2023[column_D_Renamed].str.replace(\",\", \".\")\n",
        "df_gold_2023[column_E_Renamed] = df_gold_2023[column_E_Renamed].str.replace(\",\", \".\")\n",
        "df_gold_2023[column_F_Renamed] = df_gold_2023[column_F_Renamed].str.replace(\",\", \".\")\n",
        "\n",
        "# Delete thousand separator units in Volume column\n",
        "df_gold_2023[column_G_Renamed] = df_gold_2023[column_G_Renamed].str.replace(\".\", \"\")\n",
        "\n",
        "# Delete illegal char \"-\" in Volume\n",
        "df_gold_2023[column_G_Renamed] = df_gold_2023[column_G_Renamed].str.replace(\"-\", \"0\")\n",
        "\n",
        "df_gold_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_gold_2023[column_B_Renamed] = df_gold_2023[column_B_Renamed].astype(\"float64\")\n",
        "df_gold_2023[column_C_Renamed] = df_gold_2023[column_C_Renamed].astype(\"float64\")\n",
        "df_gold_2023[column_D_Renamed] = df_gold_2023[column_D_Renamed].astype(\"float64\")\n",
        "df_gold_2023[column_E_Renamed] = df_gold_2023[column_E_Renamed].astype(\"float64\")\n",
        "df_gold_2023[column_F_Renamed] = df_gold_2023[column_F_Renamed].astype(\"float64\")\n",
        "df_gold_2023[column_G_Renamed] = df_gold_2023[column_G_Renamed].astype(\"int64\")\n",
        "\n",
        "df_gold_2023.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Brent 2023\n",
        "\n",
        "Brent 2023 csv needs these format corrections:\n",
        "\n",
        "- Rename columns\n",
        "- Set . as decimal separator token\n",
        "- set 2 float positions\n",
        "- Convert object to float64\n",
        "- Delete . from Volume cells (we don't need . to indicate thousand units)\n",
        "- Catch illegal values in Volume column \"-\" in a 185 row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "# df_brent_2023.head(None) show all rows\n",
        "df_brent_2023.iloc[180:190] # Show specific range rows, lets see a \"-\" in the serial, we need to transform it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now in our 2023 Study we will merge previous table information (ibex and ipc and euribor and gold 2023) with same format dates and same column name in this case against brent 2023 table\n",
        "# First we normalize columns name in input table brent 2023\n",
        "df_brent_2023 = df_brent_2023.rename(columns={'Fecha': 'Date', 'Abrir': 'Brent Open','Máx.': 'Brent High','Mín.': 'Brent Low','Cierre': 'Brent Close','Cierre ajus': 'Brent Adj Close','Volumen': 'Brent Volume'})\n",
        "\n",
        "# We can define variables to use in another cells\n",
        "column_A_Renamed = 'Date'\n",
        "column_B_Renamed = 'Brent Open'\n",
        "column_C_Renamed = 'Brent High'\n",
        "column_D_Renamed = 'Brent Low'\n",
        "column_E_Renamed = 'Brent Close'\n",
        "column_F_Renamed = 'Brent Adj Close'\n",
        "column_G_Renamed = 'Brent Volume'\n",
        "\n",
        "df_brent_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "# Delete . from volume, no need thousand units separator\n",
        "df_brent_2023[column_B_Renamed] = df_brent_2023[column_B_Renamed].str.replace(\",\", \".\")\n",
        "df_brent_2023[column_C_Renamed] = df_brent_2023[column_C_Renamed].str.replace(\",\", \".\")\n",
        "df_brent_2023[column_D_Renamed] = df_brent_2023[column_D_Renamed].str.replace(\",\", \".\")\n",
        "df_brent_2023[column_E_Renamed] = df_brent_2023[column_E_Renamed].str.replace(\",\", \".\")\n",
        "df_brent_2023[column_F_Renamed] = df_brent_2023[column_F_Renamed].str.replace(\",\", \".\")\n",
        "\n",
        "df_brent_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_brent_2023[column_B_Renamed] = df_brent_2023[column_B_Renamed].astype(\"float64\")\n",
        "df_brent_2023[column_C_Renamed] = df_brent_2023[column_C_Renamed].astype(\"float64\")\n",
        "df_brent_2023[column_D_Renamed] = df_brent_2023[column_D_Renamed].astype(\"float64\")\n",
        "df_brent_2023[column_E_Renamed] = df_brent_2023[column_E_Renamed].astype(\"float64\")\n",
        "df_brent_2023[column_F_Renamed] = df_brent_2023[column_F_Renamed].astype(\"float64\")\n",
        "\n",
        "df_brent_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "int(float(df_brent_2023[column_G_Renamed][3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete . in Volume cells, no need thousand separator\n",
        "df_brent_2023[column_G_Renamed] = df_brent_2023[column_G_Renamed].str.replace(\".\", \"\")\n",
        "\n",
        "df_brent_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need to fix 185 row Volumen value, its not a numeric, we will convert it to 0\n",
        "df_brent_2023[column_G_Renamed] = df_brent_2023[column_G_Renamed].str.replace(\"-\", \"0\")\n",
        "df_brent_2023[column_G_Renamed] = df_brent_2023[column_G_Renamed].astype(\"int64\")\n",
        "\n",
        "df_brent_2023.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Euro/Dolar 2023\n",
        "\n",
        "Euro/Dolar 2023 csv needs these format corrections:\n",
        "\n",
        "- Rename columns\n",
        "- Set . as decimal separator token\n",
        "- set 2 float positions\n",
        "- Convert object to float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_dolar_euro_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual data types\n",
        "df_dolar_euro_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns\n",
        "df_dolar_euro_2023 = df_dolar_euro_2023.rename(columns={'Fecha': 'Date', 'Abrir': 'Eur-USD Open','Máx.': 'Eur-USD High','Mín.': 'Eur-USD Low','Cierre': 'Eur-USD Close','Cierre ajus': 'Eur-USD Adj Close'})\n",
        "df_dolar_euro_2023\n",
        "\n",
        "# We can define variables to use in another cells\n",
        "column_A_Renamed = 'Date'\n",
        "column_B_Renamed = 'Eur-USD Open'\n",
        "column_C_Renamed = 'Eur-USD High'\n",
        "column_D_Renamed = 'Eur-USD Low'\n",
        "column_E_Renamed = 'Eur-USD Close'\n",
        "column_F_Renamed = 'Eur-USD Adj Close'\n",
        "\n",
        "df_dolar_euro_2023.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_dolar_euro_2023[column_B_Renamed] = df_dolar_euro_2023[column_B_Renamed].str.replace(\",\", \".\")\n",
        "df_dolar_euro_2023[column_C_Renamed] = df_dolar_euro_2023[column_C_Renamed].str.replace(\",\", \".\")\n",
        "df_dolar_euro_2023[column_D_Renamed] = df_dolar_euro_2023[column_D_Renamed].str.replace(\",\", \".\")\n",
        "df_dolar_euro_2023[column_E_Renamed] = df_dolar_euro_2023[column_E_Renamed].str.replace(\",\", \".\")\n",
        "df_dolar_euro_2023[column_F_Renamed] = df_dolar_euro_2023[column_F_Renamed].str.replace(\",\", \".\")\n",
        "\n",
        "df_dolar_euro_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert , to . for decimal delimiter token\n",
        "df_dolar_euro_2023[column_B_Renamed] = df_dolar_euro_2023[column_B_Renamed].astype(\"float64\")\n",
        "df_dolar_euro_2023[column_C_Renamed] = df_dolar_euro_2023[column_C_Renamed].astype(\"float64\")\n",
        "df_dolar_euro_2023[column_D_Renamed] = df_dolar_euro_2023[column_D_Renamed].astype(\"float64\")\n",
        "df_dolar_euro_2023[column_E_Renamed] = df_dolar_euro_2023[column_E_Renamed].astype(\"float64\")\n",
        "df_dolar_euro_2023[column_F_Renamed] = df_dolar_euro_2023[column_F_Renamed].astype(\"float64\")\n",
        "\n",
        "df_dolar_euro_2023.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Formatter Excess Mortality 2023\n",
        "\n",
        "Excess Mortality 2023 csv needs these format corrections:\n",
        "\n",
        "- Crop columns, we only need OBS_VALUE and TIME_PERIOD\n",
        "- Rename columns\n",
        "- Format Dates 2023-02 from to 2023-02-01\n",
        "- Expand table by dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual situation\n",
        "df_excess_mortality_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual data types\n",
        "df_excess_mortality_2023.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ok, we'll need only two columns, dates and values\n",
        "df_excess_mortality_reduced_2023 = df_excess_mortality_2023[['TIME_PERIOD', 'OBS_VALUE']]\n",
        "df_excess_mortality_reduced_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns\n",
        "df_excess_mortality_reduced_2023 = df_excess_mortality_reduced_2023.rename(columns={'TIME_PERIOD': 'Date', 'OBS_VALUE': 'Excess Mortality UE %'})\n",
        "df_excess_mortality_reduced_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standarize the dates before expansion\n",
        "df_excess_mortality_reduced_2023['Date'] = pd.to_datetime(df_excess_mortality_reduced_2023['Date'],format='%Y-%m').dt.strftime('%Y-%m-%d')\n",
        "df_excess_mortality_reduced_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we need expand the table\n",
        "\n",
        "# We can define variables to use in another cells\n",
        "column_A_Renamed = 'Date'\n",
        "column_B_Renamed = 'Excess Mortality UE %'\n",
        "\n",
        "# Declare new Dataframe\n",
        "df_excess_mortality_expanded_2023 = pd.DataFrame()\n",
        "df_excess_mortality_expanded_2023 = pd.DataFrame(columns=[column_A_Renamed, column_B_Renamed])\n",
        "# Variables column_x_Renamed are initialized in previos cell execution\n",
        "\n",
        "for i in df_excess_mortality_reduced_2023.index:\n",
        "\n",
        "    instantDate = datetime.datetime.strptime(df_excess_mortality_reduced_2023['Date'][i], '%Y-%m-%d')\n",
        "    year = instantDate.year\n",
        "    month = instantDate.month\n",
        "    num_days = calendar.monthrange(year, month)[1]\n",
        "    days = [datetime.date(year, month, day).strftime('%Y-%m-%d') for day in range(1, num_days+1)]\n",
        "\n",
        "    for d in days:\n",
        "      # Add values to new dataframe\n",
        "      df_excess_mortality_expanded_2023.loc[len(df_excess_mortality_expanded_2023.index)] = [d, df_excess_mortality_reduced_2023[column_B_Renamed][i]]\n",
        "\n",
        "df_excess_mortality_expanded_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To check table info after crop columns and expansion dates\n",
        "df_excess_mortality_expanded_2023.info(verbose=True, show_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBk0K8UazCQ_"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex 2023***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "bSqiaUsPYTtu",
        "outputId": "fe22bcec-0b9b-4e5a-d17f-1c1ec99b6698"
      },
      "outputs": [],
      "source": [
        "# Now in our 2023 Study we will merge ipc and ibex table information with same format dates and same column name in this case\n",
        "dfm_ibex_ipc_2023 = df_ibex_2023.merge(df_ipc_2023_expanded, on=\"Date\")\n",
        "dfm_ibex_ipc_2023\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check if result merged series has duplicated rows\n",
        "dfm_ibex_ipc_2023.duplicated(keep=False).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Me4ZjCjuObw"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex & Euribor 2023***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "2nk9k9dMLPOQ",
        "outputId": "16c510da-aac8-40da-8f49-66ee1538eec2"
      },
      "outputs": [],
      "source": [
        "# Merge tables\n",
        "dfm_ibex_ipc_euribor_2023 = dfm_ibex_ipc_2023.merge(df_euribor_2023, on=\"Date\")\n",
        "dfm_ibex_ipc_euribor_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check if result merged series has duplicated rows\n",
        "dfm_ibex_ipc_euribor_2023.duplicated(keep=False).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8 rows duplicated after merge tables, we need to drop them, its important ignore index otherwise deleted rows will lost that indexes\n",
        "dfm_ibex_ipc_euribor_2023_dropped = dfm_ibex_ipc_euribor_2023.drop_duplicates(subset=[\"Date\"], ignore_index=True)\n",
        "dfm_ibex_ipc_euribor_2023_dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih2LHT7jLPmG"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex & Gold 2023***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "wOqtQysYQ9FQ",
        "outputId": "11c35a22-4389-458a-89ee-2b0908ca569e"
      },
      "outputs": [],
      "source": [
        "# Merge tables\n",
        "dfm_ibex_ipc_euribor_gold_2023 = dfm_ibex_ipc_euribor_2023_dropped.merge(df_gold_2023, on=\"Date\")\n",
        "dfm_ibex_ipc_euribor_gold_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check if result merged series has duplicated rows\n",
        "dfm_ibex_ipc_euribor_gold_2023.duplicated(keep=False).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do8OEEh1LgBH"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex & Gold & Brent 2023***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "9cFX_LEdVvgY",
        "outputId": "a306f790-a397-4079-8094-9ff801fbaed3"
      },
      "outputs": [],
      "source": [
        "# Merge tables\n",
        "dfm_ibex_ipc_euribor_gold_brent_2023 = dfm_ibex_ipc_euribor_gold_2023.merge(df_brent_2023, on=\"Date\")\n",
        "dfm_ibex_ipc_euribor_gold_brent_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check if result merged series has duplicated rows\n",
        "dfm_ibex_ipc_euribor_gold_2023.duplicated(keep=False).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ZP4tptLljg"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex & Gold & Brent & Dolar/Euro 2023***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "bep0e7VSY8kw",
        "outputId": "72571a09-511f-4787-b7fd-6811ea2e4f30"
      },
      "outputs": [],
      "source": [
        "# Merge tables\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_2023 = dfm_ibex_ipc_euribor_gold_brent_2023.merge(df_dolar_euro_2023, on=\"Date\")\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check if result merged series has duplicated rows\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_2023.duplicated(keep=False).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yC2wJ1UhPss"
      },
      "source": [
        "# ***Merge Tables IPC & Ibex & Gold & Brent & Dolar/Euro & Excess Mortality 2023***\n",
        "\n",
        "WARNING: Due to pending January/December 2023 merge will crop both months"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1294
        },
        "id": "-1XWbb2yhawF",
        "outputId": "ff0bb53d-fd65-4d5c-f898-103dc8a19c78"
      },
      "outputs": [],
      "source": [
        "# Merge tables\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023 = dfm_ibex_ipc_euribor_gold_brent_eurUSD_2023.merge(df_excess_mortality_expanded_2023, on=\"Date\")\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ***Control Merge Result***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Resume Tables Size***\n",
        "This sections only shows size tables information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_count_ibex_2023 = len(df_ibex_2023)\n",
        "row_count_ipc_2023 = len(df_ipc_2023_expanded)\n",
        "row_count_euribor_2023 = len(df_euribor_2023)\n",
        "row_count_gold_2023 = len(df_gold_2023)\n",
        "row_count_brent_2023 = len(df_brent_2023)\n",
        "row_count_dolareu_2023 = len(df_dolar_euro_2023)\n",
        "row_count_mort_2023 = len(df_excess_mortality_expanded_2023)\n",
        "\n",
        "print ('Rows Ibex 2023 \\t\\t\\t---> \\t' + str(row_count_ibex_2023))\n",
        "print ('Rows IPC 2023 \\t\\t\\t---> \\t' + str(row_count_ipc_2023))\n",
        "print ('Rows Euribor 2023 \\t\\t---> \\t' + str(row_count_euribor_2023))\n",
        "print ('Rows Gold 2023 \\t\\t\\t---> \\t' + str(row_count_gold_2023))\n",
        "print ('Rows Brent 2023 \\t\\t---> \\t' + str(row_count_brent_2023))\n",
        "print ('Rows USD/Eur 2023 \\t\\t---> \\t' + str(row_count_dolareu_2023))\n",
        "print ('Rows Excess Mortality 2023 \\t---> \\t' + str(row_count_mort_2023))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Data Check Integration***\n",
        "This function is important to check data merge integration, to eval this operation we will recover every date in result series and check values in original tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST important DELETE later\n",
        "\"\"\"\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-02-01', 'Ibex Open'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-02-01', 'Excess Mortality UE %'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-02-01', 'Eur-USD Open'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-02-01', 'Brent Volume'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-08-08', 'Ibex Open'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-08-08', 'Excess Mortality UE %'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-08-08', 'Eur-USD Open'] = 9999\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.loc[dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023['Date'] == '2023-08-08', 'Brent Volume'] = 9999\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not Equals Values in column Ibex Open --> 9999.0 - 9048.0 - Please review row index: 0\n",
            "Not Equals Values in column Brent Volume--> 9999 - 28085 - Please review row index: 0\n",
            "Not Equals Values in column Eur-USD Open--> 9999.0 - 1.0861 - Please review row index: 0\n",
            "Not Equals Values in column Excess Mortality UE %--> 9999.0 - -1.1 - Please review row index: 0\n",
            "Not Equals Values in column Ibex Open --> 9999.0 - 9292.099609 - Please review row index: 109\n",
            "Not Equals Values in column Brent Volume--> 9999 - 29154 - Please review row index: 109\n",
            "Not Equals Values in column Eur-USD Open--> 9999.0 - 1.0959 - Please review row index: 109\n",
            "Not Equals Values in column Excess Mortality UE %--> 9999.0 - 4.1 - Please review row index: 109\n",
            "Gold Dataframe is broken, please review inconsistence markers - Errors: 8\n"
          ]
        }
      ],
      "source": [
        "# Now check the integrity ITERATE ALGORITHM\n",
        "sum_errors = 0\n",
        "for index, row in dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.iterrows():\n",
        "    date_analysis = row[\"Date\"]\n",
        "   \n",
        "    # Match values with Ibex35 df, Ibex 35 has 6 columns\n",
        "    k=1 # index column of merged table\n",
        "    for x in range (6):\n",
        "        pos = x+1\n",
        "        value = df_ibex_2023[df_ibex_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "        current_value = row.iloc[pos]\n",
        "        if current_value != value:\n",
        "            print(\"Not Equals Values in column \" + df_ibex_2023.columns[pos] + \" --> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "            sum_errors = sum_errors + 1\n",
        "        k = k+1\n",
        "\n",
        "    # Match values with IPC df, IPC has 4 columns \n",
        "    for x in range (3):\n",
        "        pos = x+1\n",
        "        value = df_ipc_2023_expanded[df_ipc_2023_expanded[\"Date\"] == date_analysis].values[0][pos] \n",
        "        current_value = row.iloc[k]\n",
        "        if current_value != value:\n",
        "            print(\"Not Equals Values in column \" + df_ipc_2023_expanded.columns[pos] + \" --> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "            sum_errors = sum_errors + 1\n",
        "        k = k+1\n",
        "\n",
        "    # Match values with Euribor df, Euribor has 1 column\n",
        "    pos = 1\n",
        "    value = df_euribor_2023[df_euribor_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "    current_value = row.iloc[k]\n",
        "    if current_value != value:\n",
        "        print(\"Not Equals Values in column \" + df_euribor_2023.columns[pos] + \" --> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "        sum_errors = sum_errors + 1\n",
        "    k = k+1\n",
        "    \n",
        "    # Match values with Gold df, Gold has 6 columns\n",
        "    for x in range (6):\n",
        "        pos = x+1\n",
        "        value = df_gold_2023[df_gold_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "        current_value = row.iloc[k]\n",
        "        if current_value != value:\n",
        "            print(\"Not Equals Values in column \" + df_gold_2023.columns[pos] + \"--> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "            sum_errors = sum_errors + 1\n",
        "        k = k+1\n",
        "    \n",
        "    # Match values with Brent df, Brent has 6 columns\n",
        "    for x in range (6):\n",
        "        pos = x+1\n",
        "        value = df_brent_2023[df_brent_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "        current_value = row.iloc[k]\n",
        "        if current_value != value:\n",
        "            print(\"Not Equals Values in column \" + df_brent_2023.columns[pos] + \"--> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "            sum_errors = sum_errors + 1\n",
        "        k = k+1\n",
        "    \n",
        "    # Match values with Euro/Dolar df, Euro/Dolar has 5 columns\n",
        "    for x in range (5):\n",
        "        pos = x+1\n",
        "        value = df_dolar_euro_2023[df_dolar_euro_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "        current_value = row.iloc[k]\n",
        "        if current_value != value:\n",
        "            print(\"Not Equals Values in column \" + df_dolar_euro_2023.columns[pos] + \"--> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "            sum_errors = sum_errors + 1\n",
        "        k = k+1\n",
        "    \n",
        "    # Match values with Excess Mortality df, Health Status has 1 column\n",
        "    pos = 1\n",
        "    value = df_excess_mortality_expanded_2023[df_excess_mortality_expanded_2023[\"Date\"] == date_analysis].values[0][pos] \n",
        "    current_value = row.iloc[k]\n",
        "    if current_value != value:\n",
        "        print(\"Not Equals Values in column \" + df_excess_mortality_expanded_2023.columns[pos] + \"--> \" + str(current_value) + ' - ' + str(value) + ' - Please review row index: ' + str(index))\n",
        "        sum_errors = sum_errors + 1\n",
        "    k = k+1\n",
        "\n",
        "if sum_errors == 0:\n",
        "    print(\"Gold Dataframe is coherent\")\n",
        "else:\n",
        "    print(\"Gold Dataframe is broken, please review inconsistence markers - Errors: \" + str(sum_errors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 179 entries, 0 to 178\n",
            "Data columns (total 29 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Date                   179 non-null    object \n",
            " 1   Ibex Open              179 non-null    float64\n",
            " 2   Ibex High              179 non-null    float64\n",
            " 3   Ibex Low               179 non-null    float64\n",
            " 4   Ibex Close             179 non-null    float64\n",
            " 5   Ibex Adj Close         179 non-null    float64\n",
            " 6   Ibex Volume            179 non-null    int64  \n",
            " 7   IPC Interanual %       179 non-null    float64\n",
            " 8   IPC Acum Jan %         179 non-null    float64\n",
            " 9   IPC Month Variation %  179 non-null    float64\n",
            " 10  Euribor Type           179 non-null    float64\n",
            " 11  Gold Open              179 non-null    float64\n",
            " 12  Gold High              179 non-null    float64\n",
            " 13  Gold Low               179 non-null    float64\n",
            " 14  Gold Close             179 non-null    float64\n",
            " 15  Gold Adj Close         179 non-null    float64\n",
            " 16  Gold Volume            179 non-null    int64  \n",
            " 17  Brent Open             179 non-null    float64\n",
            " 18  Brent High             179 non-null    float64\n",
            " 19  Brent Low              179 non-null    float64\n",
            " 20  Brent Close            179 non-null    float64\n",
            " 21  Brent Adj Close        179 non-null    float64\n",
            " 22  Brent Volume           179 non-null    int64  \n",
            " 23  Eur-USD Open           179 non-null    float64\n",
            " 24  Eur-USD High           179 non-null    float64\n",
            " 25  Eur-USD Low            179 non-null    float64\n",
            " 26  Eur-USD Close          179 non-null    float64\n",
            " 27  Eur-USD Adj Close      179 non-null    float64\n",
            " 28  Excess Mortality UE %  179 non-null    float64\n",
            "dtypes: float64(25), int64(3), object(1)\n",
            "memory usage: 40.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# Let's check the field types, its important avoid object types, use float or int\n",
        "dfm_ibex_ipc_euribor_gold_brent_eurUSD_mortality_2023.info(verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
